# -*- coding: utf-8 -*-
"""seamless_m4t_custom_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_w7cE_SX4LyJ3XU53Qfpej7JE8DaH95g

# SeamlessM4T S2ST Finetuning - Custom Dataset

Hindi ↔ Odia ↔ Urdu | Domains: GEN, GOV, HLT

**Flow**: Finetune → Test (General + Domain-wise)

## 1. Installation
"""

!pip install -q git+https://github.com/huggingface/transformers.git sentencepiece
!pip install -q accelerate torchaudio soundfile openpyxl
!pip install -q "datasets<3.0.0" sacrebleu jiwer unbabel-comet
!pip install -q torchcodec  # Required for newer torchaudio
print("Done! Restart runtime: Runtime -> Restart runtime")

"""## 2. Setup & Mount Drive"""

from google.colab import drive
drive.mount('/content/drive')

import os, json, torch, torchaudio
import pandas as pd
from tqdm.notebook import tqdm
from IPython.display import Audio, display

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

SAVE_DIR = "/content/checkpoints"
os.makedirs(SAVE_DIR, exist_ok=True)

# === UPDATE YOUR PATH ===
DRIVE_BASE = "/content/drive/MyDrive/EACL"

TRAIN_DIR = f"{DRIVE_BASE}/Training"
TEST_DIR = f"{DRIVE_BASE}/Testing"

print(f"Train exists: {os.path.exists(TRAIN_DIR)}")
print(f"Test exists: {os.path.exists(TEST_DIR)}")

"""## 3. Load Model"""

from transformers import AutoProcessor, SeamlessM4TModel
import time

MODEL_ID = "facebook/hf-seamless-m4t-medium"

# Use fp32 for training stability
DTYPE = torch.float32

processor = AutoProcessor.from_pretrained(MODEL_ID)
model = SeamlessM4TModel.from_pretrained(MODEL_ID, torch_dtype=DTYPE).to(device)
print(f"Loaded: {sum(p.numel() for p in model.parameters()):,} params (dtype={DTYPE})")

LANG_CODES = {"hi": "hin", "od": "ory", "ur": "urd"}
LANG_NAMES = {"hi": "Hindi", "od": "Odia", "ur": "Urdu"}
TEXT_COLS = {"ur": 0, "hi": 1, "od": 2}  # Excel: A=Urdu, B=Hindi, C=Odia

"""## 4. Data Loader"""

def get_audio_path(base_dir, lang, domain, idx, split="Train"):
    lang_folder = {"hi": "Hindi", "od": "Odia", "ur": "Urdu"}[lang]
    lang_code = {"hi": "Hi", "od": "Od", "ur": "Ur"}[lang]

    if split == "Train":
        # Training: Speeches/Hindi/Hindi_HLT/Train_Hi_Hlt_M_1.wav
        folder_domain = {"gen": "Gen", "gov": "Gov", "hlt": "HLT"}[domain.lower()]
        domain_folder = f"{lang_folder}_{folder_domain}"
        file_domain = {"gen": "Gen", "gov": "Gov", "hlt": "Hlt"}[domain.lower()]
        filename = f"{split}_{lang_code}_{file_domain}_M_{idx}.wav"
        return os.path.join(base_dir, "Speeches", lang_folder, domain_folder, filename)
    else:
        # Testing: Test_data/Test_Hindi/Hindi_Gen/Test_Hi_gen_M_1.wav
        folder_domain = {"gen": "Gen", "gov": "Gov", "hlt": "Hlt"}[domain.lower()]
        domain_folder = f"{lang_folder}_{folder_domain}"
        # gen is lowercase, Gov and Hlt are capitalized in filename
        file_domain = {"gen": "gen", "gov": "Gov", "hlt": "Hlt"}[domain.lower()]
        filename = f"Test_{lang_code}_{file_domain}_M_{idx}.wav"
        return os.path.join(base_dir, "Test_data", f"Test_{lang_folder}", domain_folder, filename)

def get_excel_path(base_dir, domain, split="Train"):
    if split == "Train":
        files = {"gen": "HinUrdOd_Gen_Clean .xlsx", "gov": "HinUrOd_Gov_Clean.xlsx", "hlt": "HinUrOd_HLT_Clean.xlsx"}
        return os.path.join(base_dir, files[domain.lower()])
    else:  # Test - Excel files are at Testing/ root, NOT inside Test_data
        files = {"gen": "test_hi_ur_od_gen_clean.xlsx", "gov": "test_hi_ur_od_gov_clean.xlsx", "hlt": "test_hi_ur_od_hlt_clean.xlsx"}
        return os.path.join(base_dir, files[domain.lower()])

def load_data(base_dir, domain, src, tgt, max_n=None, split="Train", debug=False):
    # Test Excel has header row, Training doesn't
    header_row = 0 if split == "Test" else None
    df = pd.read_excel(get_excel_path(base_dir, domain, split), header=header_row)
    samples, errors, missing_files, load_errors = [], 0, 0, 0
    first_missing = None
    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f"{domain}-{src}→{tgt}"):
        if max_n and len(samples) >= max_n: break
        path = get_audio_path(base_dir, src, domain, idx + 1, split)
        if not os.path.exists(path):
            missing_files += 1
            if first_missing is None: first_missing = path
            continue
        try:
            # Try torchaudio first, fallback to soundfile
            try:
                wav, sr = torchaudio.load(path)
                wav = wav.squeeze().numpy()
            except:
                import soundfile as sf
                wav, sr = sf.read(path)
            samples.append({"audio": wav, "sr": sr,
                           "src_text": str(row.iloc[TEXT_COLS[src]]),
                           "tgt_text": str(row.iloc[TEXT_COLS[tgt]]), "domain": domain})
        except Exception as e:
            load_errors += 1
            if load_errors <= 3: print(f"  Load error [{path}]: {e}")
    errors = missing_files + load_errors
    print(f"{domain}: {len(samples)} loaded, {errors} errors (missing: {missing_files}, load_err: {load_errors})")
    if first_missing: print(f"  First missing: {first_missing}")
    return samples

def load_all_domains(base_dir, src, tgt, max_per=None, split="Train"):
    all_data = []
    for d in ["gen", "gov", "hlt"]:
        all_data.extend(load_data(base_dir, d, src, tgt, max_per, split))
    print(f"Total: {len(all_data)}")
    return all_data

# Debug: Check TEST folder structure
import os

print("="*60)
print("DEBUG: TEST FOLDER STRUCTURE")
print("="*60)

# Check Test_data folder
test_data_path = f"{TEST_DIR}/Test_data"
print(f"\n1. Contents of {test_data_path}:")
if os.path.exists(test_data_path):
    for item in os.listdir(test_data_path):
        print(f"   - {item}")
else:
    print("   PATH DOES NOT EXIST!")

# Check what's inside Test_Hindi (or Hindi)
for folder_name in ["Test_Hindi", "Hindi"]:
    check_path = f"{TEST_DIR}/Test_data/{folder_name}"
    print(f"\n2. Contents of {check_path}:")
    if os.path.exists(check_path):
        for item in os.listdir(check_path):
            print(f"   - {item}")
        break
    else:
        print("   PATH DOES NOT EXIST!")

# Check generated path for test
test_path = get_audio_path(TEST_DIR, "hi", "gen", 1, "Test")
print(f"\n3. Generated TEST path: {test_path}")
print(f"   Exists: {os.path.exists(test_path)}")

# Check parent folder
parent = os.path.dirname(test_path)
print(f"\n4. Parent folder: {parent}")
print(f"   Exists: {os.path.exists(parent)}")
if os.path.exists(parent):
    files = os.listdir(parent)[:3]
    print(f"   First 3 files: {files}")

# Check Excel path
excel_path = get_excel_path(TEST_DIR, "gen", "Test")
print(f"\n5. Excel path: {excel_path}")
print(f"   Exists: {os.path.exists(excel_path)}")

"""## 5. Load Training Data"""

SRC, TGT = "od", "ur"  # Hindi → Urdu (change as needed)
MAX_PER_DOMAIN = 500  # Limit samples per domain for faster training (500 × 3 = 1500 total)

print(f"\nLoading {LANG_NAMES[SRC]} → {LANG_NAMES[TGT]} (max {MAX_PER_DOMAIN} per domain)")
train_data = load_all_domains(TRAIN_DIR, SRC, TGT, max_per=MAX_PER_DOMAIN, split="Train")

"""## 6. Finetuning"""

from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW

class DS(Dataset):
    def __init__(self, data, proc, tgt):
        self.data = data
        self.proc = proc
        self.tgt = tgt
        self.tgt_lang = LANG_CODES[tgt]
        self.lang_token = f"__{self.tgt_lang}__"
        self.lang_id = proc.tokenizer.convert_tokens_to_ids(self.lang_token)
        if self.lang_id == proc.tokenizer.unk_token_id:
            print(f"WARNING: tokenizer missing {self.lang_token}; labels may be misaligned.")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, i):
        s = self.data[i]
        audio = s["audio"]
        if s["sr"] != 16000:
            audio = torchaudio.functional.resample(torch.tensor(audio), s["sr"], 16000).numpy()
        if len(audio) > 15 * 16000:
            audio = audio[:15 * 16000]

        inp = self.proc(audio=audio, return_tensors="pt", sampling_rate=16000)

        self.proc.tokenizer.tgt_lang = self.tgt_lang
        lab = self.proc.tokenizer(text_target=s["tgt_text"], return_tensors="pt", truncation=True, max_length=256)
        ids = lab["input_ids"].squeeze()
        if ids.dim() == 0:
            ids = ids.unsqueeze(0)

        # Fix label alignment: drop leading </s> if followed by lang token
        dec_start_id = getattr(getattr(globals().get("model", None), "generation_config", None), "decoder_start_token_id", None)
        if dec_start_id is None:
            dec_start_id = getattr(self.proc.tokenizer, "eos_token_id", None)

        if (
            dec_start_id is not None
            and self.lang_id != self.proc.tokenizer.unk_token_id
            and ids.numel() > 1
            and ids[0].item() == int(dec_start_id)
            and ids[1].item() == int(self.lang_id)
        ):
            ids = ids[1:]  # Drop leading </s>

        return {"input_features": inp["input_features"].squeeze(), "labels": ids}


def collate(batch):
    mf = max(b["input_features"].shape[-1] for b in batch)
    ml = max(b["labels"].shape[0] for b in batch)
    feats, labs = [], []
    for b in batch:
        f, l = b["input_features"], b["labels"]
        if (pf := mf - f.shape[-1]) > 0:
            f = torch.nn.functional.pad(f, (0, pf))
        if (pl := ml - l.shape[0]) > 0:
            l = torch.nn.functional.pad(l, (0, pl), value=-100)
        feats.append(f)
        labs.append(l)
    return {"input_features": torch.stack(feats), "labels": torch.stack(labs)}

def finetune(data, tgt, epochs=2, lr=1e-5, eval_every=100, save_best=True, save_final=True):
    print(f"\n{'='*50}\nFINETUNING: {len(data)} samples\n{'='*50}")
    print(f"[ckpt] save_best={save_best} save_final={save_final}")

    tgt_code = LANG_CODES[tgt]

    # Split 90/10 for train/val
    split_idx = int(len(data) * 0.9)
    train_dl = DataLoader(DS(data[:split_idx], processor, tgt), batch_size=1, shuffle=True, collate_fn=collate)
    val_dl = DataLoader(DS(data[split_idx:], processor, tgt), batch_size=1, collate_fn=collate)
    print(f"Train: {len(train_dl)}, Val: {len(val_dl)}")

    # CRITICAL: Freeze speech encoder to prevent catastrophic forgetting
    frozen_count = 0
    trainable_count = 0
    for name, param in model.named_parameters():
        if "text_decoder" in name or "lm_head" in name:
            param.requires_grad = True
            trainable_count += 1
        else:
            param.requires_grad = False
            frozen_count += 1
    print(f"Frozen {frozen_count} params, training {trainable_count} params (text_decoder + lm_head only)")

    trainable_params = [p for p in model.parameters() if p.requires_grad]
    opt = AdamW(trainable_params, lr=lr)

    model_dtype = next(model.parameters()).dtype
    use_amp = device.type == "cuda"
    use_scaler = use_amp and (model_dtype == torch.float32)
    scaler = torch.amp.GradScaler("cuda") if use_scaler else None

    model.train()
    best, step = float("inf"), 0

    for ep in range(epochs):
        for batch in tqdm(train_dl, desc=f"Ep{ep+1}"):
            opt.zero_grad(set_to_none=True)
            try:
                input_feats = batch["input_features"].to(device=device, dtype=model_dtype)
                labels = batch["labels"].to(device)

                if use_amp:
                    with torch.amp.autocast("cuda"):
                        out = model(input_features=input_feats, labels=labels, tgt_lang=tgt_code)
                else:
                    out = model(input_features=input_feats, labels=labels, tgt_lang=tgt_code)

                if use_scaler:
                    scaler.scale(out.loss).backward()
                    scaler.unscale_(opt)
                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=1.0)
                    scaler.step(opt)
                    scaler.update()
                else:
                    out.loss.backward()
                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=1.0)
                    opt.step()

                step += 1
            except RuntimeError as e:
                if "memory" in str(e):
                    torch.cuda.empty_cache()
                    continue
                raise

            if step % eval_every == 0:
                model.eval()
                with torch.no_grad():
                    vl = 0.0
                    for vb in val_dl:
                        vfeats = vb["input_features"].to(device=device, dtype=model_dtype)
                        vlabs = vb["labels"].to(device)
                        if use_amp:
                            with torch.amp.autocast("cuda"):
                                vout = model(input_features=vfeats, labels=vlabs, tgt_lang=tgt_code)
                        else:
                            vout = model(input_features=vfeats, labels=vlabs, tgt_lang=tgt_code)
                        vl += vout.loss.item()
                    vl /= max(len(val_dl), 1)

                # Handle NaN val_loss
                if torch.isnan(torch.tensor(vl)) or torch.isinf(torch.tensor(vl)):
                    print(f"Step {step}: val_loss=NaN/Inf (skipping)")
                    model.train()
                    continue

                print(f"Step {step}: val_loss={vl:.4f}")
                if vl < best:
                    best = vl
                    if save_best:
                        print("[ckpt] New best! Saving...")
                        _t0 = time.time()
                        model.save_pretrained(f"{SAVE_DIR}/best")
                        processor.save_pretrained(f"{SAVE_DIR}/best")
                        print(f"[ckpt] Saved in {time.time()-_t0:.1f}s")
                    else:
                        print("[ckpt] New best! (save_best=False, skipping)")
                model.train()

    if save_final:
        print("[ckpt] Saving FINAL checkpoint...")
        _t0 = time.time()
        model.save_pretrained(f"{SAVE_DIR}/final")
        processor.save_pretrained(f"{SAVE_DIR}/final")
        print(f"[ckpt] Saved FINAL in {time.time()-_t0:.1f}s")
    else:
        print("[ckpt] Skipping FINAL save (save_final=False)")

    print(f"Done! Best: {best:.4f}")
    return model

# Fast debug run: set save_best=False, save_final=False to skip slow checkpoint saves
# For production: set both to True
ft = finetune(train_data, TGT, epochs=5, eval_every=100, save_best=False, save_final=False)

"""## 7. Testing - Metrics"""

import sacrebleu
from jiwer import wer as calc_wer

try:
    from comet import download_model, load_from_checkpoint
    comet_model = load_from_checkpoint(download_model("Unbabel/wmt22-comet-da"))
    COMET_OK = True
except: COMET_OK = False

def metrics(hyps, refs, srcs=None):
    v = [(h, r, s or "") for h, r, s in zip(hyps, refs, srcs or [""] * len(hyps)) if h.strip() and r.strip()]
    if not v: return {"bleu": 0, "chrf": 0, "comet": 0, "wer": 1}
    h, r, s = [x[0] for x in v], [x[1] for x in v], [x[2] for x in v]
    res = {"bleu": sacrebleu.corpus_bleu(h, [r]).score, "chrf": sacrebleu.corpus_chrf(h, [r]).score,
           "wer": sum(calc_wer(ref, hyp) for ref, hyp in zip(r, h)) / len(h)}
    if COMET_OK and srcs:
        try: res["comet"] = comet_model.predict([{"src": a, "mt": b, "ref": c} for a, b, c in zip(s, h, r)], batch_size=8, gpus=1).system_score
        except: res["comet"] = 0
    else: res["comet"] = 0
    return res

def translate(audio, sr, tgt):
    if sr != 16000:
        audio = torchaudio.functional.resample(torch.tensor(audio), sr, 16000).numpy()

    inputs = processor(audio=audio, return_tensors="pt", sampling_rate=16000)
    model_dtype = next(model.parameters()).dtype
    inputs = {
        k: (v.to(device=device, dtype=model_dtype) if torch.is_tensor(v) and v.is_floating_point() else v.to(device))
        for k, v in inputs.items()
    }

    tgt_code = LANG_CODES[tgt]

    # Patch t2u/vocoder maps for Odia (ory) which isn't in speech synthesis list
    t2u_map = getattr(model.generation_config, "t2u_lang_code_to_id", {}) or {}
    vocoder_map = getattr(model.generation_config, "vocoder_lang_code_to_id", {}) or {}
    text_map = getattr(model.generation_config, "text_decoder_lang_to_code_id", {}) or {}

    if tgt_code not in t2u_map and tgt_code in text_map:
        if t2u_map:
            t2u_map[tgt_code] = t2u_map.get("hin") or next(iter(t2u_map.values()))
            model.generation_config.t2u_lang_code_to_id = t2u_map
        if vocoder_map and tgt_code not in vocoder_map:
            vocoder_map[tgt_code] = vocoder_map.get("hin") or next(iter(vocoder_map.values()))
            model.generation_config.vocoder_lang_code_to_id = vocoder_map

    use_amp = device.type == "cuda" and model_dtype == torch.float16
    from contextlib import nullcontext
    amp_ctx = torch.amp.autocast("cuda") if use_amp else nullcontext()

    with torch.no_grad(), amp_ctx:
        out = model.generate(**inputs, tgt_lang=tgt_code, generate_speech=False)

    seq = out.sequences if hasattr(out, "sequences") else out
    if hasattr(seq, "detach"):
        seq = seq.detach()
    if hasattr(seq, "cpu"):
        seq = seq.cpu()

    return processor.tokenizer.batch_decode(seq, skip_special_tokens=True)[0]

def evaluate(samples, tgt, n=None):
    if n: samples = samples[:n]
    hyps, refs, srcs = [], [], []
    for s in tqdm(samples, desc="Testing"):
        try:
            hyps.append(translate(s["audio"], s["sr"], tgt))
            refs.append(s["tgt_text"]); srcs.append(s["src_text"])
        except Exception as e: print(f"Err: {e}")
    return metrics(hyps, refs, srcs)

"""## 8. General Test (All Domains)"""

model.eval()

print("\n" + "="*60)
print(f"GENERAL TEST: {LANG_NAMES[SRC]} → {LANG_NAMES[TGT]} (All Domains)")
print("="*60)

test_data = load_all_domains(TEST_DIR, SRC, TGT, split="Test")
results_general = evaluate(test_data, TGT, n=100)  # Test on 100 samples

print(f"\nBLEU: {results_general['bleu']:.2f}")
print(f"ChrF: {results_general['chrf']:.2f}")
print(f"COMET: {results_general['comet']:.4f}")
print(f"WER: {results_general['wer']:.4f}")

"""## 9. Domain-wise Test"""

print("\n" + "#"*60)
print("DOMAIN-WISE TEST")
print("#"*60)

domain_results = {}

for domain in ["gen", "gov", "hlt"]:
    print(f"\n--- {domain.upper()} ---")
    data = load_data(TEST_DIR, domain, SRC, TGT, max_n=50, split="Test")
    if data:
        res = evaluate(data, TGT)
        domain_results[domain] = res
        print(
            f"BLEU: {res['bleu']:.2f}, ChrF: {res['chrf']:.2f}, COMET: {res['comet']:.4f}, WER: {res['wer']:.4f}"
        )

# Summary
print("\n" + "="*60)
print("DOMAIN SUMMARY")
print("="*60)
print(f"{'Domain':<10} {'BLEU':>10} {'ChrF':>10} {'COMET':>10} {'WER':>10}")
print("-"*57)
for d, r in domain_results.items():
    print(f"{d.upper():<10} {r['bleu']:>10.2f} {r['chrf']:>10.2f} {r['comet']:>10.4f} {r['wer']:>10.4f}")

"""## 10. Save Results"""

results = {
    "pair": f"{SRC}->{TGT}",
    "general": results_general,
    "domains": domain_results
}

with open(f"{SAVE_DIR}/results_{SRC}_{TGT}.json", "w") as f:
    json.dump(results, f, indent=2)

print("Saved!")
print(json.dumps(results, indent=2))